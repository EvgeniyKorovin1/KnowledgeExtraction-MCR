{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pdfreader\n",
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "Z8-l71QF1JsY",
        "outputId": "e3104de2-18ca-45ef-8ec3-528ca35393fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfreader in /usr/local/lib/python3.10/dist-packages (0.1.12)\n",
            "Requirement already satisfied: pycryptodome>=3.9.9 in /usr/local/lib/python3.10/dist-packages (from pdfreader) (3.17)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from pdfreader) (8.4.0)\n",
            "Requirement already satisfied: bitarray>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pdfreader) (2.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pdfreader) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pdfreader) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Wand>=0.6.10\n",
            "  Downloading Wand-0.6.11-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.1\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (40.0.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: Wand, Pillow, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed Pillow-9.5.0 Wand-0.6.11 pdfminer.six-20221105 pdfplumber-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haqkbuSByfCq",
        "outputId": "c13129e4-8a46-46ea-ce55-645f7d9bb5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import PyPDF2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import os"
      ],
      "metadata": {
        "id": "OYAhUFyS393G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к папке с PDF-файлами\n",
        "pdf_folder_path = \"/content/Docs/\""
      ],
      "metadata": {
        "id": "wbgcxhC13rKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проход по каждому PDF-файлу в папке и извлечение текста\n",
        "for filename in os.listdir(pdf_folder_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        with pdfplumber.open(os.path.join(pdf_folder_path, filename)) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        # Удаление ненужных символов\n",
        "        text = re.sub('[^а-яА-Я0-9\\s]', '', text)\n",
        "        # Токенизация текста\n",
        "        tokens = word_tokenize(text)\n",
        "        # Удаление стоп-слов\n",
        "        stop_words = set(stopwords.words('russian'))\n",
        "        tokens = [word for word in tokens if not word in stop_words]\n",
        "        # Предобработка текста здесь\n",
        "\n",
        "        # Сохранение текста в файл\n",
        "        with open(os.path.join(pdf_folder_path, filename[:-4] + \".txt\"), \"w\") as text_file:\n",
        "            text_file.write(text)"
      ],
      "metadata": {
        "id": "IecelJVH4QAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import string"
      ],
      "metadata": {
        "id": "cgaZE7h9ADlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка документов для обучения модели\n",
        "doc1 = open('/content/Docs/BMP-13.txt', 'r').read()\n",
        "doc2 = open('/content/Docs/GOLD_Report_Russian_2014.txt', 'r').read()\n",
        "doc3 = open('/content/Docs/federal_klinicheskie_rekomendaciy_hobl.txt', 'r').read()"
      ],
      "metadata": {
        "id": "A6PR_GozAF_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сбор всех документов в один\n",
        "corpus = doc1 + doc2 + doc3\n",
        "\n",
        "# Очистка текста от знаков пунктуации и приведение к нижнему регистру\n",
        "corpus = corpus.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Разбиение на предложения\n",
        "sentences = corpus.split('\\n')"
      ],
      "metadata": {
        "id": "Yr8QuDUrAOe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание токенизатора на основе текста\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "gY7v7Uy0AVpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание матрицы векторов предложений на основе токенизатора\n",
        "input_sequences = []\n",
        "for sentence in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Максимальная длина последовательности входных данных\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Заполнение входных данных нулями, чтобы все последовательности были одинаковой длины\n",
        "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "1zXICNIOAZ8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Максимальная длина последовательности входных данных\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Заполнение входных данных нулями, чтобы все последовательности были одинаковой длины\n",
        "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Создание массива входных данных и меток\n",
        "x_train = input_sequences[:, :-1]\n",
        "y_train = input_sequences[:, -1]\n",
        "\n",
        "# Создание модели Transformer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_sequence_len-1))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
        "model.add(tf.keras.layers.LSTM(64))\n",
        "model.add(tf.keras.layers.Dense(len(tokenizer.word_index)+1, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(x_train, y_train, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qyP1j4QAgAS",
        "outputId": "35a8a601-68f8-46b6-d6f2-9caa4dd057db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2925/2925 [==============================] - 268s 90ms/step - loss: 8.4957\n",
            "Epoch 2/50\n",
            "2925/2925 [==============================] - 256s 87ms/step - loss: 8.0315\n",
            "Epoch 3/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 7.8253\n",
            "Epoch 4/50\n",
            "2925/2925 [==============================] - 250s 85ms/step - loss: 7.6141\n",
            "Epoch 5/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 7.3677\n",
            "Epoch 6/50\n",
            "2925/2925 [==============================] - 251s 86ms/step - loss: 7.1062\n",
            "Epoch 7/50\n",
            "2925/2925 [==============================] - 250s 85ms/step - loss: 6.8525\n",
            "Epoch 8/50\n",
            "2925/2925 [==============================] - 250s 85ms/step - loss: 6.6133\n",
            "Epoch 9/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 6.3783\n",
            "Epoch 10/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 6.1641\n",
            "Epoch 11/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 5.9659\n",
            "Epoch 12/50\n",
            "2925/2925 [==============================] - 247s 85ms/step - loss: 5.7742\n",
            "Epoch 13/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 5.5955\n",
            "Epoch 14/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 5.4359\n",
            "Epoch 15/50\n",
            "2925/2925 [==============================] - 252s 86ms/step - loss: 5.2861\n",
            "Epoch 16/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 5.1441\n",
            "Epoch 17/50\n",
            "2925/2925 [==============================] - 253s 86ms/step - loss: 5.0160\n",
            "Epoch 18/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 4.9030\n",
            "Epoch 19/50\n",
            "2925/2925 [==============================] - 252s 86ms/step - loss: 4.7853\n",
            "Epoch 20/50\n",
            "2925/2925 [==============================] - 251s 86ms/step - loss: 4.6871\n",
            "Epoch 21/50\n",
            "2925/2925 [==============================] - 252s 86ms/step - loss: 4.5937\n",
            "Epoch 22/50\n",
            "2925/2925 [==============================] - 254s 87ms/step - loss: 4.4999\n",
            "Epoch 23/50\n",
            "2925/2925 [==============================] - 253s 86ms/step - loss: 4.4223\n",
            "Epoch 24/50\n",
            "2925/2925 [==============================] - 250s 86ms/step - loss: 4.3446\n",
            "Epoch 25/50\n",
            "2925/2925 [==============================] - 252s 86ms/step - loss: 4.2687\n",
            "Epoch 26/50\n",
            "2925/2925 [==============================] - 251s 86ms/step - loss: 4.2073\n",
            "Epoch 27/50\n",
            "2925/2925 [==============================] - 252s 86ms/step - loss: 4.1470\n",
            "Epoch 28/50\n",
            "2925/2925 [==============================] - 250s 85ms/step - loss: 4.0778\n",
            "Epoch 29/50\n",
            "2925/2925 [==============================] - 251s 86ms/step - loss: 4.0304\n",
            "Epoch 30/50\n",
            "2925/2925 [==============================] - 251s 86ms/step - loss: 3.9766\n",
            "Epoch 31/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 3.9332\n",
            "Epoch 32/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.8862\n",
            "Epoch 33/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.8379\n",
            "Epoch 34/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.7979\n",
            "Epoch 35/50\n",
            "2925/2925 [==============================] - 247s 84ms/step - loss: 3.7608\n",
            "Epoch 36/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.7212\n",
            "Epoch 37/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.6858\n",
            "Epoch 38/50\n",
            "2925/2925 [==============================] - 247s 84ms/step - loss: 3.6557\n",
            "Epoch 39/50\n",
            "2925/2925 [==============================] - 250s 85ms/step - loss: 3.6181\n",
            "Epoch 40/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.5890\n",
            "Epoch 41/50\n",
            "2925/2925 [==============================] - 246s 84ms/step - loss: 3.5598\n",
            "Epoch 42/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 3.5364\n",
            "Epoch 43/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.5027\n",
            "Epoch 44/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.4766\n",
            "Epoch 45/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.4489\n",
            "Epoch 46/50\n",
            "2925/2925 [==============================] - 247s 84ms/step - loss: 3.4266\n",
            "Epoch 47/50\n",
            "2925/2925 [==============================] - 249s 85ms/step - loss: 3.3991\n",
            "Epoch 48/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.3858\n",
            "Epoch 49/50\n",
            "2925/2925 [==============================] - 248s 85ms/step - loss: 3.3616\n",
            "Epoch 50/50\n",
            "2925/2925 [==============================] - 250s 86ms/step - loss: 3.3404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24d85dba00>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Загрузка предварительно обученной модели и токенизатора\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "#model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Описание функции для генерации текста на основе введенного текста\n",
        "def generate_text(model, tokenizer, prompt, length):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    output = model.generate(input_ids=input_ids, max_length=length, do_sample=True)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "JD_XWlCCBnjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Использование функции для генерации текста\n",
        "prompt = 'температура'\n",
        "length = 500\n",
        "recommendation = generate_text(model, tokenizer, prompt, length)\n",
        "print(recommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-h4oXlByRFj",
        "outputId": "2c7d4a8b-2d61-4db5-a873-03863ae4c989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "температурату Эдытра пладовео защеступии: утлия просмер в дазаботчееск задь инік. Наеде бребы роспуй вбрениета. Увог разодя вачестя, за Соомека сэл, хорогима клэщя винтил влодой. Июлиеской просмер и видоноду ритемыниюческиа.тельных и всерудье нами ораврость оэвенкова. Сётурёщицию отьа бы прире и фирогецитно руший: помльное не доку ма маароенская руший. Наеде инік, клектуные Вушныв разодя всерудье правевительное сормытельное. Онаделя с навеже мушнаад, за Ру\n"
          ]
        }
      ]
    }
  ]
}